{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"DS202W - ✏️ W10 Summative\"\n",
        "author: <47083>\n",
        "output: html\n",
        "self-contained: true\n",
        "jupyter: python3\n",
        "engine: jupyter\n",
        "python: \"/opt/anaconda3/bin/python\"\n",
        "editor:\n",
        "  render-on-save: true\n",
        "  preview: true\n",
        "---\n",
        "\n",
        "\n",
        "# Part 1 - Pandas and Lets Plot (Exploratory Data Analysis)\n",
        "\n",
        "## Overview of steps for part 1\n",
        "\n",
        "\n",
        "1. Importing the data/prepare for exploratory data analysis\n",
        "2. Explore data and derive insights\n",
        "3. Answer the following questions:\n",
        "  a. What are the years with the top 10 highest number of total wars? How many of those years (and which ones) overlap with the years with the top 10 nominal money issues?\n",
        "  b.  Similarly, what are the years with the top 10 highest number of disasters? How many of those years (and which ones) overlap with the years with the top 10 nominal money issues?\n",
        "  c.  Create a single plot that shows the evolution over time of CPI, total wars, disasters and nominal money issues (be mindful of variable scaling!). What does this plot tell you?\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Preliminary Exploratory Data Analysis\n",
        "1. Importing the necessary libraries  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from lets_plot import *\n",
        "LetsPlot.setup_html()\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2.  Explore data and derive insights\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Load the data into a data frame called yuan\n",
        "yuan = pd.read_stata(\"Data/yuan_inflation_data.dta\")\n",
        "\n",
        "#data exploration\n",
        "print(\"Dataset information:\")\n",
        "print(yuan.info())\n",
        "\n",
        "#first 10 rows with a parapgraph break to get a clear viewing of the data\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(yuan.head(10))\n",
        "\n",
        "\n",
        "#.descibe to get summary statistics \n",
        "print(\"\\nBasic statistics:\")\n",
        "print(yuan.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "3. Answer the following questions:\n",
        "\n",
        "  ### 3a. What are the years with the top 10 highest number of total wars? How many of those years (and which ones) overlap with the years with the top 10 nominal money issues?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# create a new df with the year and totalwar \n",
        "top_wars = yuan[['year', 'totalwar']]\n",
        "# sort the dataframe by the totalwar column in descending order and select the top 10\n",
        "top_wars = top_wars.sort_values(by='totalwar', ascending=False).head(10)\n",
        "\n",
        "\n",
        "#same thing for nominal money issues\n",
        "top10_nominal_money = yuan[['year', 'nominal']]\n",
        "top10_nominal_money = top10_nominal_money.sort_values(by='nominal', ascending=False).head(10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### I am transforming each column of years from its original form into a Python set, in order to find the intersection of the two sets.\n",
        "\n",
        "table |\n",
        "|------|---------|\n",
        "| 1352 | 40 |\n",
        "| 1275 | 30 |\n",
        "| 1355 | 26 |\n",
        "| 1328 | 17 |\n",
        "| 1325 | 12 |\n",
        "| 1353 | 11 |\n",
        "| 1327 | 11 |\n",
        "| 1331 | 11 |\n",
        "| 1354 | 10 |\n",
        "| 1323 | 10 |\n",
        "---\n",
        "\n",
        "The top 10 years with the most nominal money issues are \n",
        "Top 10 years with highest nominal money issues:\n",
        "\n",
        "| year | nominal |\n",
        "|------|---------|\n",
        "| 1355 | 49500000 |\n",
        "| 1310 | 36259200 |\n",
        "| 1354 | 34500000 |\n",
        "| 1353 | 19500000 |\n",
        "| 1352 | 19500000 |\n",
        "| 1312 | 11211680 |\n",
        "| 1311 | 10900000 |\n",
        "| 1313 | 10200000 |\n",
        "| 1314 | 10100000 |\n",
        "| 1302 | 10000000 |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "overlapping_years = set(top_wars['year']).intersection(set(top10_nominal_money['year']))\n",
        "print(overlapping_years)\n",
        "\n",
        "#set creates a data structure  of unique items\n",
        "# intersection finds the common items between the two sets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###### There are **4 years** that overlap**\n",
        "#### The years that overlap are **1352, 1353, 1354, 1355**  \n",
        "\n",
        "\n",
        "\n",
        "### 3b.  Similarly, what are the years with the top 10 highest number of disasters? How many of those years (and which ones) overlap with the years with the top 10 nominal money issues?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#we essentially need to repeat the same process as above, but with the disaster column\n",
        "top10_disasters= yuan[['year', 'disaster']]\n",
        "top10_disasters = top10_disasters.sort_values(by='disaster', ascending=False).head(10)\n",
        "\n",
        "\n",
        "print(\"Top 10 years with highest number of disasters:\")\n",
        "print(top10_disasters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#utilize set function again to find the intersection of the two sets (disasters and nominal money issues)\n",
        "years_overlap = set(top10_disasters['year']).intersection(set(top10_nominal_money['year']))\n",
        "print(\"\\nOverlapping years between disasters and nominal money issues:\")\n",
        "print(years_overlap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3b. Because nothing printed **no years overlap!**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 3c. Create a single plot that shows the evolution over time of CPI, total wars, disasters and nominal money issues (be mindful of variable scaling!). What does this plot tell you?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# we need to normalize the data to make it comparable\n",
        "\n",
        "#use the formula min  max scaling - it transforms each value by subtracting the minimum value and dividing by the range (maximum minus minimum), \n",
        "yuan['CPI_normalized'] = (yuan['cpi'] - yuan['cpi'].min()) / (yuan['cpi'].max() - yuan['cpi'].min())\n",
        "\n",
        "yuan['wars_normalized'] = (yuan['totalwar'] - yuan['totalwar'].min()) / (yuan['totalwar'].max() - yuan['totalwar'].min())\n",
        "\n",
        "\n",
        "yuan['disasters_normalized'] = (yuan['disaster'] - yuan['disaster'].min()) / (yuan['disaster'].max() - yuan['disaster'].min())\n",
        "\n",
        "\n",
        "yuan['nominal_normalized'] = (yuan['nominal'] - yuan['nominal'].min()) / (yuan['nominal'].max() - yuan['nominal'].min())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "#### Note before plotting: I believe that the boxplot is the best way to visualize the distribution of the data as it shows the median, quartiles, and outliers, which help for comparison of multiple variables. However I will use more than 1 plot in order to make sure the data is being visualized thoroughly.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#we are using the standard scaler to normalize the data this time. \n",
        "scaler = StandardScaler()\n",
        "\n",
        "#new df with scaled data\n",
        "scaled_data = scaler.fit_transform(yuan[['cpi', 'totalwar', 'disaster', 'nominal']])\n",
        "\n",
        "#new columns for clarity\n",
        "yuan_scaled = pd.DataFrame(scaled_data, columns=['CPI_normalized', 'wars_normalized', 'disasters_normalized', 'nominal_normalized'])\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(yuan['year'], yuan_scaled['CPI_normalized'], label='CPI', color='blue', linewidth=2)\n",
        "plt.plot(yuan['year'], yuan_scaled['wars_normalized'], label='Total Wars', color='red', linewidth=2)\n",
        "plt.plot(yuan['year'], yuan_scaled['disasters_normalized'], label='Disasters', color='green', linewidth=2)\n",
        "plt.plot(yuan['year'], yuan_scaled['nominal_normalized'], label='Nominal Money Issues', color='orange', linewidth=2)\n",
        "plt.title(' CPI, Total Wars, Disasters, and Nominal Money Issues  Over Time of the Yuan Dynasty')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Z-score')\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid(True, which='both', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#first plot boxplot, this uses the normalized data. \n",
        "plt.figure(figsize=(10, 6))\n",
        "boxplot_data = [yuan_scaled['CPI_normalized'], yuan_scaled['wars_normalized'], \n",
        "                yuan_scaled['disasters_normalized'], yuan_scaled['nominal_normalized']]\n",
        "plt.boxplot(boxplot_data, labels=['CPI', 'Wars', 'Disasters', 'Nominal'])\n",
        "plt.title('Distribution Comparison of CPI, Total Wars, Disasters, and Nominal Money Issues - Yuan Dynasty (1260-1355)')\n",
        "plt.ylabel('Normalized Value')\n",
        "plt.grid(axis='y', alpha=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis of the data\n",
        "## We can break down the data into 2 parts: \n",
        "  1. Each variable individually.\n",
        "  2. The data as a whole.\n",
        "\n",
        "\n",
        "## Breakdown each of the variables that we analyzed.\n",
        "\n",
        "### - CPI\n",
        "The first plot shows the normalized data of all the variables over time. We can see that CPI is the most stable, however, after 1340 there was a spike, and ends with a z score of around 3.8. This makes sense as in the paper it is stated after 1340 population started to decline \"population started to decline \"Population figures during the mid-Yuan period (1290−333) remained unchanged but started to recover after 1330 and peaked in 1341.51 After that, the population started to decline.\" (Guan, Palma, and Wu 2024). \n",
        "\n",
        "\n",
        "#### - Total Wars\n",
        "In terms of the other variables, we can see that the total wars, is very volatile with sharp spikes, paticularly around 1275, with a z score of 4.2, and ends with a score of 3.5 in 1355 after its peak a few years prior. This is makes sense as it suggests that the total wars were not as frequent as the CPI, but when they were frequent, they were devestating. \n",
        "\n",
        "#### - Nominal Money Issues\n",
        "Although having a peak at the end, nominal money issues is by far the most stable, and the lowest of all the variables. It spikes in 1310, which can be explained by the abondonment of the The third paper money, the zhidachao, the the third paper money issued by the issued by the third Yuan emperor, KülügYuan, in 1310. It had a It had a significantly higher value than previous currencies:\n",
        "  1 guan of zhidachao was equivalent to 5 guan of zhiyuanchao\n",
        "  1 guan of zhidachao was equivalent to 25 guan of zhongtongcha \n",
        "However, the zhidachoa was only in cirualtion for 1 year, as soon after,  Külüg died suddenly in 1311, his successor Ayurbarwada Khan abandoned the zhidachao and restored the previous two paper currencies (zhongtongchao and zhiyuanchao). The issuance of zhidachao represented a massive spike in the nominal money supply, with annual issuance reaching 36 million ding in 1310, compared to just 5 million ding when zhiyuanchao was being issued. This can explain why the spike in 1310 is so high. \n",
        "\n",
        "#### - Disasters\n",
        "The disasters are arguably the most volatile of all the variables based on the z-score plot. There a few peaks as seen in the 1290s and the 1330s. There was years of tranquility prior to the 1290s, as in the paper, it states, \"After the initial years of tranquillity, from 1285, the empire began to suffer from various natural disasters\" (Frequency of natural disasters. Source: Chen et al., A chronicle of natural and man-made disasters in China, pp. 1068−220.). \n",
        "\n",
        "### Data as a whole\n",
        "As mentioned, each of these variables individually have differing scales, ranges, and historical context that make them difficult to compare. However, we can still derive that CPI was the most affected by the other variables, as CPI when measuring inflation, there is no such thing as one factor/variable that affects it, it is a cumulation of many factors. These factors we measured, total wars, disasters, and nominal money issues, all have an effect on the CPI. With that in mind, the CPI was still relatively stable, and with a simple plot, it is hard to tell the true effect the other variables, if there was a significant effect. If there were to be more extensive analysis, we could use a correlation matrix to see the relationship between the variables, or another model \n",
        " 📊 😅...\n",
        " \n",
        "---\n",
        "\n",
        "\n",
        "# Part 2: Create regression models (45 marks)\n",
        "\n",
        "\n",
        "## Overview of steps for part 2\n",
        "1. Create a baseline linear regression model:\n",
        "  a. Create the training and test sets:\n",
        "  b. linear regression model that predicts the CPI\n",
        "  c. Residuals plot\n",
        "  d. Model evaluation/performance metrics\n",
        "\n",
        "2.  Come up with my own feature selection or feature engineering or model selection strategy and try to get a better model performance than you had before. \n",
        "  a. Model selection choice and justification\n",
        "  b. Code\n",
        "  c. Explaination of choices\n",
        "  d. Model performance/evaluation\n",
        "  e. Comparison to baseline model\n",
        "\n",
        "\n",
        "### 1a."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "#1a. Create the training and test sets\n",
        "#split data based on year\n",
        "yuan_train = yuan[yuan['year'] < 1327].copy()\n",
        "yuan_test = yuan[yuan['year'] >= 1327].copy()\n",
        "\n",
        "#target and features\n",
        "features = ['totalwar', 'disaster', 'nominal']\n",
        "target = 'cpi'\n",
        "\n",
        "# Prepare training data\n",
        "X_train = yuan_train[features]\n",
        "y_train = yuan_train[target]\n",
        "\n",
        "#1b. Linear regression model that predicts the CPI for training data\n",
        "\n",
        "# Add a constant term for the intercept\n",
        "X_train_const = sm.add_constant(X_train)\n",
        "\n",
        "# Utilize an OLS model using the training data\n",
        "ols_model = sm.OLS(y_train, X_train_const)\n",
        "results = ols_model.fit()\n",
        "\n",
        "# Print the OLS summary output for training data\n",
        "print(\"OLS Model for Training Data:\")\n",
        "print(results.summary())\n",
        "\n",
        "#1c. Residuals plot for training data\n",
        "fitted_values = results.fittedvalues\n",
        "residuals = y_train - fitted_values\n",
        "r2 = results.rsquared\n",
        "rmse = np.sqrt(mean_squared_error(y_train, fitted_values))\n",
        "\n",
        "print(\"\\nPerformance on Training Data:\")\n",
        "print(\"R-squared:\", np.round(r2, 2))\n",
        "print(\"Root Mean Squared Error (RMSE):\", np.round(rmse, 2))\n",
        "\n",
        "# Plot the residuals versus the fitted values for training data\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(fitted_values, residuals, alpha=0.7, color='blue')\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.xlabel('CPI Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals Plot for Training Data')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Now the test data !! same steps as above\n",
        "# Prepare test data\n",
        "X_test = yuan_test[features]\n",
        "y_test = yuan_test[target]\n",
        "\n",
        "# Add constant term for the intercept\n",
        "X_test_const = sm.add_constant(X_test)\n",
        "\n",
        "# Fit the OLS model on the test data\n",
        "ols_test_model = sm.OLS(y_test, X_test_const)\n",
        "results_test = ols_test_model.fit()\n",
        "\n",
        "# Print the OLS summary output for test data\n",
        "print(\"\\nOLS Model for Test Data:\")\n",
        "print(results_test.summary())\n",
        "\n",
        "# Predict on the test data\n",
        "y_test_pred = results_test.predict(X_test_const)\n",
        "\n",
        "# Calculate residuals for the test data\n",
        "test_residuals = y_test - y_test_pred\n",
        "\n",
        "# Calculate performance metrics on the test data\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "print(\"\\nPerformance on Test Data:\")\n",
        "print(\"Test R-squared:\", np.round(test_r2, 2))\n",
        "print(\"Test Root Mean Squared Error (RMSE):\", np.round(test_rmse, 2))\n",
        "\n",
        "# Plot the residuals versus the fitted values for test data\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(y_test_pred, test_residuals, alpha=0.7, color='green')\n",
        "plt.axhline(0, color='red', linestyle='--')\n",
        "plt.xlabel('Fitted CPI Values (Test Data)')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residuals Plot for Test Data')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1d. Model evaluation/performance metrics\n",
        "\n",
        " ##### Model Comparison: Training data:\n",
        " Overall, the model is not horrible. Considering the r-sqaured values is 0.48, the model is moderate. It accounts for almost 50% of the variation for the CPI... in all fairness for 3 variables, it is not too bad. This makes sense however, as the CPI is not just defined by the variables we included (total wars, disasters, and nominal money issues), but also by other factors that are not included in the model. The f-statistic is less than 0.00001, which is good, thus meaning the information we included is statistically significant. \n",
        "\n",
        "The p-value for disaster and nomial p-value are 0.0000, which is significant. However, the p-value for total wars is 0.259, which is not significant. This makes some sense as the wars seen in the last plot from part 1, show that the wars were not as frequent as the other inherirent issues such as nominal money issues and disasters which followed a similar volatility. Additionally, if the wars were less frequent, they may not have had as much of an immediate or lasting impact on inflation in the same way that disasters or nominal issues did. CPI however is a special variable. This is evident when exploring the last plot from part 1, where the disasters are realievly stable **until 1340**, whre there is a massive spike.  The CPI spike in 1340 might be tied to an event not captured well in the model (such as a specific, one-time shock), that could explain why totalwar isnt significant and  other variables might be significant. Lets test my hypothesis out to create my own model. \n",
        "\n",
        "\n",
        "\n",
        "##### Model Comparison: Test data:\n",
        "The performance on test data is as follows:\n",
        "  Test R-squared: 0.71\n",
        "  Test Root Mean Squared Error (RMSE): 14.47\n",
        "\n",
        "This shows us that the test model is more accurate than the training model, as the r-squared value is higher, even though the RSME is lower. \n",
        "\n",
        "Analysis: Both models show that totalwar has little influence on CPI. The nominal variable is highly significant in both cases, which makes sense because CPI would likely be highly influenced by monetary changes. Disaster is significant in training but borderline significant in test data, which could suggest a change in the impact of disasters between the training and test periods.\n",
        "\n",
        "\n",
        "## 2: My own model : \n",
        "\n",
        "#### Features: \n",
        "I want to add more features to the model. I want to add variables howevre some variables are similar in nature, such as rebellion and total war. Others like year are not useful as it is not a variable that can be controlled or manipulated, it is simily a context variable. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# we need to create a new df with the new features\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/opt/anaconda3/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}